{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/urwa/Documents/side_projects/urban/UrbanTrafficPrediction\n"
     ]
    }
   ],
   "source": [
    "cd /home/urwa/Documents/side_projects/urban/UrbanTrafficPrediction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.lstm_utils import prepare_data_lstm, lstm_monthly_dataloader\n",
    "from utils.lstm_utils import get_device\n",
    "\n",
    "from utils.lstm_utils import evaluate_edge_monthy\n",
    "from models.models import LSTM\n",
    "\n",
    "from utils.lstm_utils import train_one_epoch, store_chekpoint, evaluate_lstm_pipeline_model, run_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'lr': 0.00034439316653688684,\n",
    " 'layers': 3,\n",
    " 'step_size': 11,\n",
    " 'gamma': 0.761795969995615,\n",
    " 'bptt': 19,\n",
    " 'dropout': 0.1227497445640586}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device(cuda=True)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/urwa/Documents/side_projects/urban/data/featureData/com_jfk.csv'\n",
    "weights_path = '/home/urwa/Documents/side_projects/urban/data/featureData/com_jfk_weights.csv'\n",
    "test_data_path='/home/urwa/Documents/side_projects/urban/data/featureData/jfk.csv'\n",
    "\n",
    "exp_dir = '/home/urwa/Documents/side_projects/urban/UrbanTrafficPrediction/data/lstm_12fold/jfk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Shape:  (8757, 113)\n",
      "Cleaned Shape:  (8757, 38)\n",
      "Target columns: 24\n",
      "Feature coumns:  13\n"
     ]
    }
   ],
   "source": [
    "dataset, targetColumns, features_cols = prepare_data_lstm(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  1\n",
      "train test split\n",
      "train shape:  (8016, 38)\n",
      "test shape:  (741, 38)\n",
      "train feature tensor shape : torch.Size([8016, 13])\n",
      "train target tensor shape : torch.Size([8016, 24])\n",
      "test feature tensor shape : torch.Size([741, 13])\n",
      "test target tensor shape : torch.Size([741, 24])\n",
      "\n",
      "sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 24]) torch.Size([19, 24])\n",
      "\n",
      " Training model...\n",
      "------- Saving checkpoint---------------\n",
      "epoch:   0 loss: 8.91559761 r2: 0.376 rmse: 308.645 mae: 9.680\n",
      "Saving model and residual\n",
      "edge r2:  0.21851823390740718\n",
      "------- Saving checkpoint---------------\n",
      "epoch:   1 loss: 5.94415740 r2: 0.562 rmse: 216.613 mae: 7.795\n",
      "Saving model and residual\n",
      "edge r2:  0.34381119502283347\n",
      "best_r2:  0.5617228564892284\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  2\n",
      "train test split\n",
      "train shape:  (8085, 38)\n",
      "test shape:  (672, 38)\n",
      "train feature tensor shape : torch.Size([8085, 13])\n",
      "train target tensor shape : torch.Size([8085, 24])\n",
      "test feature tensor shape : torch.Size([672, 13])\n",
      "test target tensor shape : torch.Size([672, 24])\n",
      "\n",
      "sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 24]) torch.Size([19, 24])\n",
      "\n",
      " Training model...\n",
      "------- Saving checkpoint---------------\n",
      "epoch:   0 loss: 9.19145571 r2: 0.378 rmse: 287.290 mae: 9.128\n",
      "Saving model and residual\n",
      "edge r2:  0.2432563688978337\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-18bc5c6fea4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_inout_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mstore_chekpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/side_projects/urban/UrbanTrafficPrediction/utils/lstm_utils.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, loss_function, train_inout_seq, device)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0msingle_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msingle_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/general/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/general/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bptt = config['bptt']\n",
    "\n",
    "R2List = []\n",
    "EdgeR2List = []\n",
    "residual_list = []\n",
    "\n",
    "\n",
    "for m in range(1,13):\n",
    "    \n",
    "    print('-------------------------------------------------')\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Month: \", m)\n",
    "\n",
    "    train_inout_seq, test_inout_seq = lstm_monthly_dataloader(dataset,features_cols, targetColumns, m,\n",
    "                                                              bptt, device)\n",
    "    \n",
    "    lstm_layers = config['layers']\n",
    "    network_size = len(targetColumns)\n",
    "    feat_size = len(features_cols)\n",
    "    dropout = config['dropout']\n",
    "    hidden_layer_size=100\n",
    "    \n",
    "    \n",
    "    model = LSTM(feat_size, network_size, hidden_layer_size, lstm_layers, dropout).to(device)\n",
    "    loss_function = nn.L1Loss()   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['step_size'], gamma=config['gamma']) \n",
    "    \n",
    "    \n",
    "    epochs = 2\n",
    "    \n",
    "    best_r2=0\n",
    "    \n",
    "    print(\"\\n Training model...\")\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        loss = train_one_epoch(model, optimizer, loss_function, train_inout_seq, device)\n",
    "        scheduler.step()\n",
    "        store_chekpoint(exp_dir, model, optimizer, scheduler)\n",
    "\n",
    "        residual, r2, rmse, mae = evaluate_lstm_pipeline_model(model, test_inout_seq, device)\n",
    "        print(f'epoch: {i:3} loss: {loss:10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_residual = residual\n",
    "            torch.save(model.state_dict(), os.path.join(exp_dir, str(m)+'.pt'))\n",
    "            np.save(os.path.join(exp_dir,str(m)+'.npy'), best_residual)\n",
    "            edge_res, edge_r2, edge_rmse, edge_mae = evaluate_edge_monthy(model, test_inout_seq, device, \n",
    "                                                                   targetColumns, weights_path, \n",
    "                                                              test_data_path, m, bptt)\n",
    "            print('Saving model and residual')\n",
    "            print('edge r2: ', edge_r2)\n",
    "            \n",
    "            \n",
    "    print(\"best_r2: \", best_r2)\n",
    "\n",
    "    R2List.append(best_r2)\n",
    "    EdgeR2List.append(edge_r2)\n",
    "    residual_list.append(best_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
