{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/urwa/Documents/side_projects/urban/UrbanTrafficPrediction\n"
     ]
    }
   ],
   "source": [
    "cd /home/urwa/Documents/side_projects/urban/UrbanTrafficPrediction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import LSTM_Pipeline\n",
    "from utils.lstm_utils import get_device, create_data_sequences, prepare_data_tensors, train_test_split_monthly\n",
    "from utils.lstm_utils import prepare_data_lstm\n",
    "from utils.lstm_utils import get_community_attachment_matix\n",
    "from utils.lstm_utils import evaluate_lstm_pipeline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'lr': 0.00034439316653688684,\n",
    " 'layers': 3,\n",
    " 'step_size': 11,\n",
    " 'gamma': 0.761795969995615,\n",
    " 'bptt': 19,\n",
    " 'dropout': 0.1227497445640586}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011598697153799081"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['lr'] = config['lr'] * config['gamma'] **4\n",
    "config['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device(cuda=False)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Shape:  (8757, 1049)\n",
      "Cleaned Shape:  (8757, 272)\n",
      "Target columns: 258\n",
      "Feature coumns:  13\n"
     ]
    }
   ],
   "source": [
    "dataset, targetColumns, features_cols = prepare_data_lstm('/home/urwa/Documents/side_projects/urban/data/featureData/jfk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>avgtemp</th>\n",
       "      <th>departure</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>participation</th>\n",
       "      <th>newsnow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>ifSnow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  maxtemp  \\\n",
       "0  2018-01-01     3  0   0    0    0    0    0    0    0  ...       18   \n",
       "1  2018-01-01     4  0   3    0    0    1    0    0    1  ...       18   \n",
       "2  2018-01-01     5  0   4    0    0    1    2    3    1  ...       18   \n",
       "3  2018-01-01     6  0   0    1    2    0    3    0    0  ...       18   \n",
       "4  2018-01-01     7  3   4    2    0    0    0    9    0  ...       18   \n",
       "\n",
       "   mintemp  avgtemp  departure  hdd  cdd  participation  newsnow  snowdepth  \\\n",
       "0        7     12.5      -21.2   52    0            0.0      0.0          0   \n",
       "1        7     12.5      -21.2   52    0            0.0      0.0          0   \n",
       "2        7     12.5      -21.2   52    0            0.0      0.0          0   \n",
       "3        7     12.5      -21.2   52    0            0.0      0.0          0   \n",
       "4        7     12.5      -21.2   52    0            0.0      0.0          0   \n",
       "\n",
       "   ifSnow  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_to_comm_file = '/home/urwa/Documents/side_projects/urban/UrbanTemporalNetworks/Data/ZonetoComm.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = '/home/urwa/Documents/side_projects/urban/urban_traffic_prediciton/pipeline/fix_attachment/jfk.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, loss_function, train_inout_seq):\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for feat,seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.initialize_hidden_cell(device)\n",
    "        y_pred = model(seq, feat)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(single_loss.item())\n",
    "    return np.mean(losses)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_chekpoint(exp_dir, model,optimizer,lr_scheduler):\n",
    "    print('------- Saving checkpoint---------------')\n",
    "    checkpoint_path = os.path.join(exp_dir,'checkpoint.pth')\n",
    "\n",
    "    torch.save({'model_state_dict': model.state_dict(),                                                 \n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': lr_scheduler.state_dict()}, \n",
    "               checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chekpoint(exp_dir, model,optimizer,lr_scheduler):\n",
    "    print('------- Loading checkpoint---------------')\n",
    "    checkpoint_path = os.path.join(exp_dir,'checkpoint.pth')\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    return model, optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_dataloader(dataset, month):\n",
    "    \n",
    "    trainData, testData = train_test_split_monthly(dataset, month)\n",
    "\n",
    "    X_train, y_train, X_test, y_test = prepare_data_tensors(trainData, testData, \n",
    "                                                            features_cols, targetColumns, device)\n",
    "\n",
    "\n",
    "    train_inout_seq = create_data_sequences(X_train,y_train, bptt)\n",
    "    test_inout_seq = create_data_sequences(X_test,y_test, bptt)\n",
    "    print(\"\\nsequences\")\n",
    "    print(train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape)\n",
    "        \n",
    "    return train_inout_seq, test_inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  1\n",
      "train test split\n",
      "train shape:  (8016, 272)\n",
      "test shape:  (741, 272)\n",
      "train feature tensor shape : torch.Size([8016, 13])\n",
      "train target tensor shape : torch.Size([8016, 258])\n",
      "test feature tensor shape : torch.Size([741, 13])\n",
      "test target tensor shape : torch.Size([741, 258])\n",
      "\n",
      "sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      " model loaded\n",
      "\n",
      " model inititalized\n",
      "722\n",
      "Pretraining R2:  0.5235885448038736\n",
      "\n",
      " Training model...\n",
      "------- Saving checkpoint---------------\n",
      "epoch:   0 loss: 0.99708172 r2: 0.479 rmse: 3.724 mae: 1.042\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e5067a12e480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_inout_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mstore_chekpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-aa69fd824f4d>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, loss_function, train_inout_seq)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msingle_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msingle_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/general/lib/python3.6/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/general/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bptt = config['bptt']\n",
    "exp_dir = 'data' \n",
    "\n",
    "R2List = []\n",
    "residual_list = []\n",
    "\n",
    "at_mat = get_community_attachment_matix(targetColumns, zone_to_comm_file)\n",
    "print(\"\\nattachment matrix\")\n",
    "print(at_mat.shape)\n",
    "\n",
    "for m in range(1,13):\n",
    "\n",
    "    \n",
    "    print('-------------------------------------------------')\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Month: \", m)\n",
    "\n",
    "    train_inout_seq, test_inout_seq = get_lstm_dataloader(dataset, m)\n",
    "    \n",
    "\n",
    "    layers = config['layers']\n",
    "    communities = 24\n",
    "    network_size = len(targetColumns)\n",
    "    feat_size = len(features_cols)\n",
    "    dropout = config['dropout']\n",
    "\n",
    "    model = LSTM_Pipeline(feat_size = feat_size, hidden_layer_size=communities,\n",
    "                 network_size=network_size, lstm_layers=layers,\n",
    "                aggregation_size=communities, dropout=dropout, at_mat=at_mat).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(pretrained_weights, map_location=device))\n",
    "    print(\"\\n model loaded\")\n",
    "\n",
    "    loss_function = nn.L1Loss()   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['step_size'], gamma=config['gamma'])\n",
    "    print(\"\\n model inititalized\")\n",
    "\n",
    "    print(len(test_inout_seq))\n",
    "    residual, r2, rmse, mae = evaluate_lstm_pipeline_model(model, test_inout_seq, device)\n",
    "    print(\"Pretraining R2: \",r2)\n",
    "\n",
    "    \n",
    "    best_r2 = r2\n",
    "    best_residual = residual\n",
    "    torch.save(model.state_dict(), os.path.join(exp_dir, str(m)+'.pt'))\n",
    "    np.save(os.path.join(exp_dir,str(m)+'.npy'), best_residual)\n",
    "\n",
    "    epochs = 60\n",
    "    \n",
    "    print(\"\\n Training model...\")\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        loss = train_one_epoch(model, optimizer, loss_function, train_inout_seq)\n",
    "        scheduler.step()\n",
    "        store_chekpoint(exp_dir, model, optimizer, scheduler)\n",
    "\n",
    "        residual, r2, rmse, mae = evaluate_lstm_pipeline_model(model, test_inout_seq, device)\n",
    "        print(f'epoch: {i:3} loss: {loss:10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_residual = residual\n",
    "            torch.save(model.state_dict(), os.path.join(exp_dir, str(m)+'.pt'))\n",
    "            np.save(os.path.join(exp_dir,str(m)+'.npy'), best_residual)\n",
    "\n",
    "    print(\"bet_r2: \", best_r2)\n",
    "\n",
    "    R2List.append(best_r2)\n",
    "    residual_list.append(best_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(R2List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.530\n",
    "0.5506309348043397\n",
    "0.5972399097890982\n",
    "0.6083282515195536\n",
    "0.6267548650792119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = config['bptt']\n",
    "\n",
    "resdf_list = []\n",
    "\n",
    "for m in range(1,13):\n",
    "    month_index  = pd.to_datetime(dataset.Date).dt.month == m\n",
    "    \n",
    "    print('-------------------------------------------------')\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Month: \", m)\n",
    "\n",
    "    testData = dataset[month_index]\n",
    "    testData = testData[bptt:]\n",
    "    date = testData['Date']\n",
    "    hour = testData['Hour']\n",
    "    \n",
    "    print(\"\\n test shape\")\n",
    "    print(testData.shape)\n",
    "\n",
    "    residual = np.load('data/'+'jfk_'+str(m)+'.npy')\n",
    "    print(\"\\n residual\")\n",
    "    print(residual.shape)\n",
    "\n",
    "    res_df = pd.DataFrame(residual)\n",
    "    res_df.columns = targetColumns\n",
    "    res_df['Date'] = testData['Date'].values\n",
    "    res_df['Hour'] = testData['Hour'].values\n",
    "    res_df = res_df[['Date', 'Hour'] + targetColumns]\n",
    "    \n",
    "    print(res_df.head())\n",
    "    resdf_list.append(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res_df = pd.concat(resdf_list)\n",
    "all_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res_df.to_csv('data/residual_jfk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attachment = torch.argmax(F.softmax(model.attachment_matrix, dim=1), dim=1).detach().cpu().numpy()\n",
    "# community_assignment = dict(zip(targetColumns, attachment))\n",
    "# community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 comm\n",
    "# 0.505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 comm\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
